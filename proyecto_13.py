'''
DescripciÃ³n del proyecto
Rusty Bargain es un servicio de venta de coches de segunda mano que estÃ¡ desarrollando una app para atraer a nuevos clientes. Gracias a esa app, puedes averiguar rÃ¡pidamente el valor de mercado de tu coche. Tienes acceso al historial, especificaciones tÃ©cnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.

A Rusty Bargain le interesa:

la calidad de la predicciÃ³n
la velocidad de la predicciÃ³n
el tiempo requerido para el entrenamiento

Instrucciones del proyecto
Descarga y examina los datos.
Entrena diferentes modelos con varios hiperparÃ¡metros (debes hacer al menos dos modelos diferentes, pero mÃ¡s es mejor. Recuerda, varias implementaciones de potenciaciÃ³n del gradiente no cuentan como modelos diferentes). El punto principal de este paso es comparar mÃ©todos de potenciaciÃ³n del gradiente con bosque aleatorio, Ã¡rbol de decisiÃ³n y regresiÃ³n lineal.
Analiza la velocidad y la calidad de los modelos.
Observaciones:

Utiliza la mÃ©trica RECM para evaluar los modelos.
La regresiÃ³n lineal no es muy buena para el ajuste de hiperparÃ¡metros, pero es perfecta para hacer una prueba de cordura de otros mÃ©todos. Si la potenciaciÃ³n del gradiente funciona peor que la regresiÃ³n lineal, definitivamente algo saliÃ³ mal.
Aprende por tu propia cuenta sobre la librerÃ­a LightGBM y sus herramientas para crear modelos de potenciaciÃ³n del gradiente (gradient boosting).
Idealmente, tu proyecto debe tener regresiÃ³n lineal para una prueba de cordura, un algoritmo basado en Ã¡rbol con ajuste de hiperparÃ¡metros (preferiblemente, bosque aleatorio), LightGBM con ajuste de hiperparÃ¡metros (prueba un par de conjuntos), y CatBoost y XGBoost con ajuste de hiperparÃ¡metros (opcional).
Toma nota de la codificaciÃ³n de caracterÃ­sticas categÃ³ricas para algoritmos simples. LightGBM y CatBoost tienen su implementaciÃ³n, pero XGBoost requiere OHE.
Puedes usar un comando especial para encontrar el tiempo de ejecuciÃ³n del cÃ³digo de celda en Jupyter Notebook. Encuentra ese comando.
Dado que el entrenamiento de un modelo de potenciaciÃ³n del gradiente puede llevar mucho tiempo, cambia solo algunos parÃ¡metros del modelo.
Si Jupyter Notebook deja de funcionar, elimina las variables excesivas por medio del operador del:

  del features_train
  
DescripciÃ³n de los datos
El dataset estÃ¡ almacenado en el archivo /datasets/car_data.csv. descargar dataset.

CaracterÃ­sticas

DateCrawled â€” fecha en la que se descargÃ³ el perfil de la base de datos
VehicleType â€” tipo de carrocerÃ­a del vehÃ­culo
RegistrationYear â€” aÃ±o de matriculaciÃ³n del vehÃ­culo
Gearbox â€” tipo de caja de cambios
Power â€” potencia (CV)
Model â€” modelo del vehÃ­culo
Mileage â€” kilometraje (medido en km de acuerdo con las especificidades regionales del conjunto de datos)
RegistrationMonth â€” mes de matriculaciÃ³n del vehÃ­culo
FuelType â€” tipo de combustible
Brand â€” marca del vehÃ­culo
NotRepaired â€” vehÃ­culo con o sin reparaciÃ³n
DateCreated â€” fecha de creaciÃ³n del perfil
NumberOfPictures â€” nÃºmero de fotos del vehÃ­culo
PostalCode â€” cÃ³digo postal del propietario del perfil (usuario)
LastSeen â€” fecha de la Ãºltima vez que el usuario estuvo activo
Objetivo

Price â€” precio (en euros)

EvaluaciÃ³n del proyecto
Hemos definido los criterios de evaluaciÃ³n para el proyecto. LÃ©elos con atenciÃ³n antes de pasar al ejercicio.

Esto es en lo que se fijarÃ¡n los revisores al examinar tu proyecto:

Â¿Seguiste todos los pasos de las instrucciones?
Â¿CÃ³mo preparaste los datos?
Â¿QuÃ© modelos e hiperparÃ¡metros consideraste?
Â¿Conseguiste evitar la duplicaciÃ³n del cÃ³digo?
Â¿CuÃ¡les son tus hallazgos?
Â¿Mantuviste la estructura del proyecto?
Â¿Mantuviste el cÃ³digo ordenado?
  
'''


'''
1. PreparaciÃ³n de Datos
'''


# Importar librerÃ­as
import lightgbm as lgb
import numpy as np
import timeit as t
import pandas as pd

from IPython.display import display
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder



# Cargar los datos
df = pd.read_csv('datasets/car_data.csv')


# ExploraciÃ³n inicial
print(df.info())
display(df.head())


'''
RevisiÃ³n y limpieza:

Eliminar columnas que probablemente no serÃ¡n Ãºtiles para el modelo, como DateCrawled, DateCreated, LastSeen, PostalCode, y NumberOfPictures.

Manejar valores nulos en columnas relevantes como VehicleType, Gearbox, FuelType, y NotRepaired.

Convertir valores categÃ³ricos a tipo category para optimizar la memoria.

Analizar y tratar posibles errores en RegistrationYear y Power.
'''


# Eliminar columnas innecesarias
df.drop(['DateCrawled', 'DateCreated', 'LastSeen', 'PostalCode', 'NumberOfPictures'], axis=1, inplace=True)


# Rellenar valores faltantes en columnas categÃ³ricas con un valor especÃ­fico o "Unknown"
df['VehicleType'].fillna('Unknown', inplace=True)
df['Gearbox'].fillna('Unknown', inplace=True)
df['FuelType'].fillna('Unknown', inplace=True)
df['NotRepaired'].fillna('Unknown', inplace=True)


# Tratar errores en 'RegistrationYear' y 'Power'
df = df[(df['RegistrationYear'] >= 1886) & (df['RegistrationYear'] <= 2024)]
df = df[df['Power'].between(1, 1000)]


# Convertir columnas categÃ³ricas
for col in ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']:
    df[col] = df[col].astype('category')


# Confirmar limpieza
print(df.info())
display(df.describe())


'''
2. Entrenamiento del Modelo
Objetivo: Probar y ajustar varios modelos, incluyendo regresiÃ³n lineal (para referencia), Ã¡rboles de decisiÃ³n, bosque aleatorio, y 
LightGBM.
'''


#  Dividir los datos en conjuntos de entrenamiento y prueba
# Definir caracterÃ­sticas y objetivo
X = df.drop('Price', axis=1)
y = df['Price']


# Dividir los datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Preprocesamiento de caracterÃ­sticas categÃ³ricas
# CodificaciÃ³n de caracterÃ­sticas categÃ³ricas para modelos que lo requieren
categorical_features = X.select_dtypes(include=['category']).columns
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],
    remainder='passthrough')


'''
Definir y entrenar modelos

Modelos a considerar:
RegresiÃ³n lineal (prueba de cordura)
Ãrbol de decisiÃ³n
Bosque aleatorio
LightGBM (recomendado para datos de alta dimensionalidad y muchas categorÃ­as)
'''


# Lista de modelos a probar
models = {
    'Linear Regression': LinearRegression(),
    'Decision Tree': DecisionTreeRegressor(random_state=42),
    'Random Forest': RandomForestRegressor(random_state=42, n_jobs=-1),
    'LightGBM': lgb.LGBMRegressor(random_state=42, n_jobs=-1)
}

# Entrenar y evaluar cada modelo
results = {}
for model_name, model in models.items():
    pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                               ('regressor', model)])
    # Entrenar
    pipeline.fit(X_train, y_train)

    # Predicciones
    y_pred = pipeline.predict(X_test)

    # EvaluaciÃ³n
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)
    results[model_name] = {'RMSE': rmse, 'R2': r2}

    print(f"{model_name} - RMSE: {rmse:.4f}, R2: {r2:.4f}")


'''
AnÃ¡lisis del Modelo
Objetivo del AnÃ¡lisis El anÃ¡lisis del modelo busca evaluar y comparar la precisiÃ³n y el rendimiento de los modelos de predicciÃ³n de precio 
de vehÃ­culos de segunda mano, con Ã©nfasis en la mÃ©trica RMSE (raÃ­z cuadrada del error cuadrÃ¡tico medio) y el coeficiente de determinaciÃ³n 
ð‘…2. Estos resultados ayudarÃ¡n a determinar el modelo que mejor equilibra precisiÃ³n y eficiencia para ser implementado en la app de 
Rusty Bargain.
'''

# Resumen de resultados
results_df = pd.DataFrame(results).T
display(results_df.sort_values(by='RMSE'))


# MediciÃ³n de tiempo de predicciÃ³n para el mejor modelo
best_model_name = results_df['RMSE'].idxmin()
best_model = models[best_model_name]


# Tiempo de predicciÃ³n
t.timeit(best_model.predict(X_test))


'''
Conclusiones del AnÃ¡lisis de Modelos y Recomendaciones

A partir de los resultados obtenidos para los modelos de regresiÃ³n lineal y Ã¡rbol de decisiÃ³n:

RegresiÃ³n Lineal

RMSE: 2914.06
RÂ²: 0.5988
Este modelo explica aproximadamente el 59.88% de la varianza en los precios y presenta un error moderado, pero no es el modelo mÃ¡s preciso. 
Debido a su simplicidad, podrÃ­a ser Ãºtil en aplicaciones donde se requiera rapidez en la predicciÃ³n, aunque en este caso no se aprovechan 
las relaciones no lineales entre variables, resultando en una predicciÃ³n menos precisa comparada con otros mÃ©todos.

Ãrbol de DecisiÃ³n

RMSE: 2146.58
RÂ²: 0.7823
El Ã¡rbol de decisiÃ³n es significativamente mÃ¡s preciso que la regresiÃ³n lineal. Con un ð‘…2 de 78.23%, este modelo es capaz de capturar 
mejor las variaciones en el precio, lo cual lo hace mÃ¡s adecuado para nuestro caso. Esto sugiere que este modelo capta relaciones 
complejas en los datos que pueden pasar desapercibidas en una regresiÃ³n lineal.
'''

'''
Modelo Seleccionado
Modelo Final: Ãrbol de DecisiÃ³n

Se seleccionÃ³ el Ã¡rbol de decisiÃ³n como modelo final debido a los siguientes factores:

PrecisiÃ³n: 
Este modelo superÃ³ a la regresiÃ³n lineal en tÃ©rminos de ð‘…2 y RMSE, mostrando una mayor capacidad para predecir precios con precisiÃ³n. 

Capacidad de Captura de Relaciones Complejas: 
El Ã¡rbol de decisiÃ³n es mÃ¡s adecuado para datos con relaciones no lineales, permitiÃ©ndole captar patrones relevantes en los datos de Rusty 
Bargain.

Balance de Velocidad y Exactitud: Aunque es mÃ¡s complejo que la regresiÃ³n lineal, el Ã¡rbol de decisiÃ³n sigue siendo relativamente rÃ¡pido 
en comparaciÃ³n con otros modelos avanzados, lo cual es beneficioso en un contexto donde la velocidad de predicciÃ³n tambiÃ©n es relevante.
'''

