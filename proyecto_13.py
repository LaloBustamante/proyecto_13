'''
DescripciÃ³n del proyecto
Rusty Bargain es un servicio de venta de coches de segunda mano que estÃ¡ desarrollando una app para atraer a nuevos clientes. Gracias a esa app, puedes averiguar rÃ¡pidamente el valor de mercado de tu coche. Tienes acceso al historial, especificaciones tÃ©cnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.

A Rusty Bargain le interesa:

la calidad de la predicciÃ³n
la velocidad de la predicciÃ³n
el tiempo requerido para el entrenamiento

Instrucciones del proyecto
Descarga y examina los datos.
Entrena diferentes modelos con varios hiperparÃ¡metros (debes hacer al menos dos modelos diferentes, pero mÃ¡s es mejor. Recuerda, varias implementaciones de potenciaciÃ³n del gradiente no cuentan como modelos diferentes). El punto principal de este paso es comparar mÃ©todos de potenciaciÃ³n del gradiente con bosque aleatorio, Ã¡rbol de decisiÃ³n y regresiÃ³n lineal.
Analiza la velocidad y la calidad de los modelos.
Observaciones:

Utiliza la mÃ©trica RECM para evaluar los modelos.
La regresiÃ³n lineal no es muy buena para el ajuste de hiperparÃ¡metros, pero es perfecta para hacer una prueba de cordura de otros mÃ©todos. Si la potenciaciÃ³n del gradiente funciona peor que la regresiÃ³n lineal, definitivamente algo saliÃ³ mal.
Aprende por tu propia cuenta sobre la librerÃ­a LightGBM y sus herramientas para crear modelos de potenciaciÃ³n del gradiente (gradient boosting).
Idealmente, tu proyecto debe tener regresiÃ³n lineal para una prueba de cordura, un algoritmo basado en Ã¡rbol con ajuste de hiperparÃ¡metros (preferiblemente, bosque aleatorio), LightGBM con ajuste de hiperparÃ¡metros (prueba un par de conjuntos), y CatBoost y XGBoost con ajuste de hiperparÃ¡metros (opcional).
Toma nota de la codificaciÃ³n de caracterÃ­sticas categÃ³ricas para algoritmos simples. LightGBM y CatBoost tienen su implementaciÃ³n, pero XGBoost requiere OHE.
Puedes usar un comando especial para encontrar el tiempo de ejecuciÃ³n del cÃ³digo de celda en Jupyter Notebook. Encuentra ese comando.
Dado que el entrenamiento de un modelo de potenciaciÃ³n del gradiente puede llevar mucho tiempo, cambia solo algunos parÃ¡metros del modelo.
Si Jupyter Notebook deja de funcionar, elimina las variables excesivas por medio del operador del:

  del features_train
  
DescripciÃ³n de los datos
El dataset estÃ¡ almacenado en el archivo /datasets/car_data.csv. descargar dataset.

CaracterÃ­sticas

DateCrawled â€” fecha en la que se descargÃ³ el perfil de la base de datos
VehicleType â€” tipo de carrocerÃ­a del vehÃ­culo
RegistrationYear â€” aÃ±o de matriculaciÃ³n del vehÃ­culo
Gearbox â€” tipo de caja de cambios
Power â€” potencia (CV)
Model â€” modelo del vehÃ­culo
Mileage â€” kilometraje (medido en km de acuerdo con las especificidades regionales del conjunto de datos)
RegistrationMonth â€” mes de matriculaciÃ³n del vehÃ­culo
FuelType â€” tipo de combustible
Brand â€” marca del vehÃ­culo
NotRepaired â€” vehÃ­culo con o sin reparaciÃ³n
DateCreated â€” fecha de creaciÃ³n del perfil
NumberOfPictures â€” nÃºmero de fotos del vehÃ­culo
PostalCode â€” cÃ³digo postal del propietario del perfil (usuario)
LastSeen â€” fecha de la Ãºltima vez que el usuario estuvo activo
Objetivo

Price â€” precio (en euros)

EvaluaciÃ³n del proyecto
Hemos definido los criterios de evaluaciÃ³n para el proyecto. LÃ©elos con atenciÃ³n antes de pasar al ejercicio.

Esto es en lo que se fijarÃ¡n los revisores al examinar tu proyecto:

Â¿Seguiste todos los pasos de las instrucciones?
Â¿CÃ³mo preparaste los datos?
Â¿QuÃ© modelos e hiperparÃ¡metros consideraste?
Â¿Conseguiste evitar la duplicaciÃ³n del cÃ³digo?
Â¿CuÃ¡les son tus hallazgos?
Â¿Mantuviste la estructura del proyecto?
Â¿Mantuviste el cÃ³digo ordenado?
  
'''


'''
1. PreparaciÃ³n de Datos
'''


# Importar librerÃ­as
import lightgbm as lgb
import numpy as np
import pandas as pd
import xgboost as xgb

from IPython.display import display
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from timeit import default_timer as timer


# Cargar los datos
df = pd.read_csv('datasets/car_data.csv')


# ExploraciÃ³n inicial
print(df.info())
display(df.head())


'''
RevisiÃ³n y limpieza:

Eliminar columnas que probablemente no serÃ¡n Ãºtiles para el modelo, como DateCrawled, DateCreated, LastSeen, PostalCode, y NumberOfPictures.

Manejar valores nulos en columnas relevantes como VehicleType, Gearbox, FuelType, y NotRepaired.

Convertir valores categÃ³ricos a tipo category para optimizar la memoria.

Analizar y tratar posibles errores en RegistrationYear y Power.
'''


# Eliminar columnas innecesarias
df.drop(['DateCrawled', 'DateCreated', 'LastSeen', 'PostalCode', 'NumberOfPictures'], axis=1, inplace=True)


# Rellenar valores faltantes en columnas categÃ³ricas con un valor especÃ­fico o "Unknown"
df['VehicleType'].fillna('Unknown', inplace=True)
df['Gearbox'].fillna('Unknown', inplace=True)
df['FuelType'].fillna('Unknown', inplace=True)
df['NotRepaired'].fillna('Unknown', inplace=True)


# Tratar errores en 'RegistrationYear' y 'Power'
df = df[(df['RegistrationYear'] >= 1886) & (df['RegistrationYear'] <= 2024)]
df = df[df['Power'].between(1, 1000)]


# Convertir columnas categÃ³ricas
for col in ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']:
    df[col] = df[col].astype('category')


# Confirmar limpieza
print(df.info())
display(df.describe())


'''
2. Entrenamiento del Modelo
Objetivo: Probar y ajustar varios modelos, incluyendo regresiÃ³n lineal (para referencia), Ã¡rboles de decisiÃ³n, bosque aleatorio, y 
LightGBM.
'''


#  Dividir los datos en conjuntos de entrenamiento y prueba
# Definir caracterÃ­sticas y objetivo
X = df.drop('Price', axis=1)
y = df['Price']


# Dividir los datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Preprocesamiento y codificaciÃ³n para modelos
categorical_features = X.select_dtypes(include=['category']).columns
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', min_frequency=0.05), categorical_features)], remainder='passthrough')


'''
Definir y entrenar modelos

Modelos a considerar:
RegresiÃ³n lineal (prueba de cordura)
Ãrbol de decisiÃ³n
Bosque aleatorio
LightGBM 
XGBoost
'''


# ConfiguraciÃ³n de modelos y ajustes de hiperparÃ¡metros bÃ¡sicos
models = {
    'Linear Regression': LinearRegression(),
    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),
    'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1),
    'LightGBM': lgb.LGBMRegressor(n_estimators=50, max_depth=10, learning_rate=0.1, random_state=42),
    'XGBoost': xgb.XGBRegressor(n_estimators=50, max_depth=10, learning_rate=0.1, random_state=42)
}

# Entrenar y evaluar cada modelo
results = {}
for model_name, model in models.items():
    print(f"\nEntrenando modelo: {model_name}")
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])
    
    start_time = timer()  # Tiempo de inicio
    pipeline.fit(X_train, y_train)
    end_time = timer()  # Tiempo final

    # Predicciones y evaluaciÃ³n
    y_pred = pipeline.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)
    results[model_name] = {'RMSE': rmse, 'R2': r2, 'Train Time (s)': end_time - start_time}

    print(f"{model_name} - RMSE: {rmse:.4f}, R2: {r2:.4f}, Train Time: {end_time - start_time:.2f} segundos")


'''
AnÃ¡lisis del Modelo:

Objetivo del AnÃ¡lisis: El anÃ¡lisis del modelo busca evaluar y comparar la precisiÃ³n y el rendimiento de los modelos de predicciÃ³n de precio 
de vehÃ­culos de segunda mano, con Ã©nfasis en la mÃ©trica RMSE (raÃ­z cuadrada del error cuadrÃ¡tico medio) y el coeficiente de determinaciÃ³n 
ğ‘…2. Estos resultados ayudarÃ¡n a determinar el modelo que mejor equilibra precisiÃ³n y eficiencia para ser implementado en la app de 
Rusty Bargain.
'''


# Resumen de resultados
results_df = pd.DataFrame(results).T
display(results_df.sort_values(by='RMSE'))


# MediciÃ³n de tiempo de predicciÃ³n para el mejor modelo
best_model_name = results_df['RMSE'].idxmin()
best_model = models[best_model_name]


# MediciÃ³n de tiempo de predicciÃ³n para el mejor modelo con pipeline completo
best_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', best_model)])

# Medir el tiempo de predicciÃ³n en el conjunto de prueba
start_time = timer()
y_pred_best = best_pipeline.predict(X_test)
end_time = timer()

# Imprimir tiempo de predicciÃ³n y mÃ©tricas de evaluaciÃ³n del mejor modelo
rmse_best = mean_squared_error(y_test, y_pred_best, squared=False)
r2_best = r2_score(y_test, y_pred_best)
print(f"Tiempo de predicciÃ³n del mejor modelo ({best_model_name}): {end_time - start_time:.4f} segundos")
print(f"RMSE del mejor modelo: {rmse_best:.4f}")
print(f"R2 del mejor modelo: {r2_best:.4f}")


'''
Conclusiones del AnÃ¡lisis de Modelos y Recomendaciones  
  
Linear Regression:

RMSE: 2890.02  
ğ‘…<sup>2</sup>: 0.6054  
Train Time: 2.50 segundos  
AnÃ¡lisis: La regresiÃ³n lineal tiene el peor rendimiento en tÃ©rminos de error (RMSE) y coeficiente de determinaciÃ³n (ğ‘…<sup>2</sup>), lo cual es esperado, ya que este modelo es lineal y no captura bien las relaciones complejas. Sin embargo, es una buena base para comparar otros modelos.  
  
Decision Tree:  

RMSE: 2095.26  
ğ‘…<sup>2</sup>: 0.7926  
Train Time: 2.21 segundos  
AnÃ¡lisis: El Ã¡rbol de decisiÃ³n mejora considerablemente el rendimiento con respecto a la regresiÃ³n lineal, reduciendo el RMSE y aumentando ğ‘…<sup>2</sup>, lo cual indica un mejor ajuste. Aunque es un modelo rÃ¡pido y simple, su rendimiento es inferior al de los otros modelos mÃ¡s avanzados.  

Random Forest:  

RMSE: 1994.40  
ğ‘…<sup>2</sup>: 0.8121  
Train Time: 23.14 segundos  
AnÃ¡lisis: El bosque aleatorio muestra una mejora significativa en comparaciÃ³n con el Ã¡rbol de decisiÃ³n, y alcanza un buen equilibrio entre RMSE y ğ‘…<sup>2</sup>. Sin embargo, el tiempo de entrenamiento es considerablemente mayor debido al ensamblado de mÃºltiples Ã¡rboles.  

LightGBM:  

RMSE: 1925.82  
ğ‘…<sup>2</sup>: 0.8248  
Train Time: 1.41 segundos  
AnÃ¡lisis: LightGBM tiene un rendimiento excelente, logrando un RMSE bajo y un ğ‘…<sup>2</sup> mÃ¡s alto en un tiempo de entrenamiento muy corto. Este modelo es eficiente y adecuado para grandes conjuntos de datos, mostrando una combinaciÃ³n de precisiÃ³n y velocidad.

XGBoost:  

RMSE: 1772.34  
ğ‘…<sup>2</sup>: 0.8516  
Train Time: 2.63 segundos  
AnÃ¡lisis: XGBoost es el mejor en tÃ©rminos de precisiÃ³n, obteniendo el RMSE mÃ¡s bajo y el ğ‘…<sup>2</sup> mÃ¡s alto entre todos los modelos. Aunque el tiempo de entrenamiento es mayor que LightGBM, el incremento en precisiÃ³n lo convierte en la mejor elecciÃ³n para este conjunto de datos.
'''

'''
Modelo Seleccionado   
  
ConclusiÃ³n General:  

Mejor Modelo: XGBoost, ya que obtiene el mejor RMSE y R<sup>2</sup>, lo que indica una precisiÃ³n superior en las predicciones.  

Modelos Alternativos: LightGBM es una excelente alternativa si el tiempo de entrenamiento es un factor importante, ya que ofrece una precisiÃ³n cercana a XGBoost en menos tiempo.  

RecomendaciÃ³n: Considerar el uso de XGBoost para este caso, ya que su mayor precisiÃ³n beneficia la predicciÃ³n del valor de los autos usados, aunque LightGBM podrÃ­a usarse si se requiere un modelo con un balance Ã³ptimo entre precisiÃ³n y velocidad.
'''

